# LLM 回應品質分類系統

本組 final project 旨在參加 [Kaggle「LLM Classification Fine-Tuning」](https://www.kaggle.com/competitions/llm-classification-finetuning)競賽，目標是透過微調大型語言模型，建立一套能對不同回應進行優劣評比的自動分類系統，並另行開發一個使用者介面（UI），讓最終使用者能輸入任意問題，系統自動產生兩個不同的回應選項，使用者可自行判斷哪個回應較佳，最後將使用者的選擇與模型的自動判斷進行比較，以評估模型的實用性與一致性。

使用者在使用時可直接輸入任意文本問題（prompt），後端便會自動產生兩組回應：一組代表「模型 A 風格」的回應，另一組代表「模型 B 風格」的回應，並會呼叫我們微調後的語言模型去進行判斷。使用者在閱讀兩者內容後，選擇他們認為較合適、較正確或較貼近需求的那個答案，並按下「投票」按鈕。系統即時紀錄使用者的選擇，並與模型原先「預測誰較佳」的結果進行比對。 

使用者完成選擇後，UI 會顯示兩個結果：一是使用者的投票結果（例如：Model_B 回應較佳），另一則是模型在同一筆資料上的自動判斷（例如：模型自動認為 Model_A 回應較佳）。若兩者一致，系統將顯示「模型判斷與使用者一致」；若不一致，則顯示「模型判斷與使用者選擇不一致」。

---

## 實驗目標

- 自動比較兩個 LLM 回應的品質，分類為「Model A 勝」、「Model B 勝」或「平手」三類。
- 適用於人類偏好標註資料，提升分類準確率與泛化能力。
- 系統需可於單一 GPU、有限記憶體下穩定運作，並支援離線部署。

---

## 系統架構與設計

### 1. 模型選擇

- **首選模型**：DistilBERT-base-uncased（輕量、效能與資源消耗平衡）。
- **可選替代**：RoBERTa-base（較高效能，資源需求略增）、ALBERT（參數更少，適合極度受限環境）。
- **三分類架構**：輸出為 Model A 勝、Model B 勝、平手，符合人類偏好決策習慣。


### 2. 數據預處理

- 輸入格式需結構化，明確標註 prompt、兩個回應內容及其長度。
- 建議加入回應長度、情感分數、複雜度等元特徵，提升模型辨識力。
- 為減少位置偏差，應隨機交換 A/B 回應順序進行數據增強。


### 3. 類別平衡

- 偏好數據常見類別不平衡（如「平手」較少），需採用類別加權或樣本增強。
- 推薦方法：
    - 使用 Focal Loss 或類似困難樣本加權策略，提升少數類別辨識能力。
    - 可考慮 SMOTE 等過採樣技術，針對少數類別合成新樣本。


### 4. 訓練與優化

- 採用早停（Early Stopping）防止過擬合，並以驗證集 log loss 或多指標監控最佳模型。
- 學習率調度（如餘弦退火）有助於提升泛化能力。
- 建議批次大小根據顯存動態調整，確保資源利用最大化。


### 5. 評估指標

- **主要指標**：
    - Log Loss（機率校準）
    - Accuracy（分類正確率）
- **偏好學習專用指標**：
    - Bradley-Terry loss（偏好建模一致性）
    - Win Rate（人類化評估）
    - Balanced Accuracy（處理不平衡）
- 可依需求加入 F1-score、Kendall’s Tau 等排序相關指標。

---

## 實驗步驟流程

1. **數據準備與預處理**
    - 整理 prompt 及兩組回應，結構化輸入格式。
    - 隨機交換回應順序進行數據增強。
    - 加入元特徵（如長度、情感分數等）。
2. **模型初始化**
    - 選擇合適輕量級預訓練模型（如 DistilBERT）。
    - 完成離線模型檔案準備，確保可在無網路環境下運行。
3. **訓練配置**
    - 設定類別加權或困難樣本損失函數。
    - 調整批次大小、學習率等超參數。
    - 實施早停與學習率調度。
4. **模型訓練**
    - 使用加權損失與數據增強資料進行訓練。
    - 監控訓練與驗證集的多項指標。
5. **模型評估與驗證**
    - 以多種指標（log loss、accuracy、Bradley-Terry loss 等）評估模型表現。
    - 進行分層抽樣，確保驗證集分布合理。
6. **推理與部署**
    - 以批次推理方式處理大量資料，提升效率。
    - 確認模型可於目標硬體環境下穩定運作。

---

## 改良方法

- **短期改良**：
    - 數據增強（如回應順序隨機化）
    - 超參數優化（網格搜尋、貝葉斯優化等）
    - 多指標 early stopping 監控
- **中期改良**：
    - 測試 RoBERTa、ALBERT 等替代模型效能
    - 實施 Focal Loss、SMOTE 等進階類別平衡策略
- **長期探索**：
    - 採用排序損失或部分排序方法提升偏好建模能力
    - 集成多模型（如 BERT、RoBERTa、DeBERTa）提升穩定性
    - 探索 Constitutional AI、DPO 等新型偏好學習技術

---

## 資源限制與競賽考量

- **記憶體與運算限制**：優先選用輕量級模型與批次動態調整，避免超過硬體上限。
- **離線運作**：所有模型與依賴需預先下載，確保無網路環境下可完整執行。
- **推理效率**：可根據硬體條件選擇 TinyBERT、ALBERT 等更輕量模型作為備援方案。
