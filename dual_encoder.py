import torch
from torch import nn
from transformers import AutoModel, PretrainedConfig
from typing import Optional

class DualTowerConfig(PretrainedConfig):
    """DualToweræ¨¡å‹çš„é…ç½®é¡"""
    model_type = "dual_tower"
    
    def __init__(
        self,
        base_model="distilbert-base-uncased",
        hidden_size=768,
        dropout=0.2,
        metadata_feature_size=5,
        metadata_fusion="dual_path",
        num_labels=3,
        **kwargs
    ):
        super().__init__(**kwargs)
        self.base_model = base_model
        self.hidden_size = hidden_size
        self.dropout = dropout
        self.metadata_feature_size = metadata_feature_size
        self.metadata_fusion = metadata_fusion
        self.num_labels = num_labels
        self.has_meta_path = metadata_feature_size > 0 and metadata_fusion == 'dual_path'
        self.classifier_input_dim = hidden_size * 6 if self.has_meta_path else hidden_size * 5

class DualTowerPairClassifier(nn.Module):
    """
    Dual-Encoder / Two-Tower æ¨¡å‹ + Metadata ç‰¹å¾µè™•ç†
    - å…±ç”¨ä¸€åº§ Transformer Encoderï¼Œå„è‡ªç·¨ç¢¼ Promptã€Response Aã€Response B  
    - ç‰¹å¾µå‘é‡: [v_p, v_a, |v_p âˆ’ v_a|, v_b, |v_p âˆ’ v_b|, metadata_features]
    - metadata é€é meta_path å¾5ç¶­å‡åˆ°768ç¶­
    - æœ€çµ‚ç‰¹å¾µ: 768 Ã— 6 = 4608 ç¶­
    - 3-é¡ softmax â†’ 0=A wins, 1=B wins, 2=Tie
    """

    config_class = DualTowerConfig

    def __init__(
        self,
        base_model: str = "distilbert-base-uncased",
        hidden_size: int = 768,
        dropout: float = 0.2,
        metadata_feature_size: int = 5,  # metadata åŸå§‹ç¶­åº¦
        metadata_fusion: str = 'dual_path',  # metadata èåˆæ–¹å¼
        config: DualTowerConfig = None,
    ):
        super().__init__()
        
        # å‰µå»ºæˆ–ä½¿ç”¨æä¾›çš„config
        if config is None:
            self.config = DualTowerConfig(
                base_model=base_model,
                hidden_size=hidden_size,
                dropout=dropout,
                metadata_feature_size=metadata_feature_size,
                metadata_fusion=metadata_fusion
            )
        else:
            self.config = config
            
        self.encoder = AutoModel.from_pretrained(self.config.base_model)
        self.dropout = nn.Dropout(self.config.dropout)
        
        # Metadata è™•ç†è·¯å¾‘ - èˆ‡ kaggle_last.py å®Œå…¨ä¸€è‡´
        self.meta_path = None
        if self.config.has_meta_path:
            self.meta_path = nn.Sequential(
                nn.Linear(self.config.metadata_feature_size, self.config.hidden_size),
                nn.ReLU(),
                nn.Linear(self.config.hidden_size, self.config.hidden_size),
                nn.ReLU()
            )
            print(f"    ğŸ’¡ å‰µå»º metadata è™•ç†è·¯å¾‘: {self.config.metadata_feature_size} -> {self.config.hidden_size} -> {self.config.hidden_size}")
        
        self.classifier = nn.Sequential(
            nn.Linear(self.config.classifier_input_dim, self.config.hidden_size),
            nn.ReLU(),
            nn.Linear(self.config.hidden_size, self.config.num_labels),
        )
        
        print(f"    ğŸ’¡ åˆ†é¡å™¨è¼¸å…¥ç¶­åº¦: {self.config.classifier_input_dim} (æœŸæœ› 4608 å¦‚æœæœ‰metadata)")

    def encode(self, ids: torch.Tensor, mask: torch.Tensor) -> torch.Tensor:
        """å›å‚³ [CLS] embedding (batch, hidden)"""
        out = self.encoder(
            input_ids=ids, attention_mask=mask, return_dict=True
        )
        return out.last_hidden_state[:, 0]

    def forward(
        self,
        p_input_ids: torch.Tensor,
        p_attention_mask: torch.Tensor,
        a_input_ids: torch.Tensor,
        a_attention_mask: torch.Tensor,
        b_input_ids: torch.Tensor,
        b_attention_mask: torch.Tensor,
        metadata_features: Optional[torch.Tensor] = None, # metadata è¼¸å…¥
        labels: Optional[torch.Tensor] = None,
    ):
        v_p = self.encode(p_input_ids, p_attention_mask)
        v_a = self.encode(a_input_ids, a_attention_mask)
        v_b = self.encode(b_input_ids, b_attention_mask)

        # æ‹¼æ¥åŸºç¤ç‰¹å¾µå‘é‡ï¼š[v_p, v_a, |v_p - v_a|, v_b, |v_p - v_b|] = 768Ã—5
        feat = torch.cat(
            [v_p, v_a, torch.abs(v_p - v_a), v_b, torch.abs(v_p - v_b)], dim=-1
        )
        
        # è™•ç† metadata ç‰¹å¾µ
        if self.meta_path and metadata_features is not None:
            # é€šé meta_path å‡ç¶­ï¼š5 -> 768 -> 768
            meta_feat = self.meta_path(metadata_features)
            # æ‹¼æ¥ï¼šåŸºç¤ç‰¹å¾µ(768Ã—5) + metadataç‰¹å¾µ(768) = 768Ã—6 = 4608
            feat = torch.cat([feat, meta_feat], dim=-1)
        elif self.meta_path:
            # å¦‚æœæ¨¡å‹æœ‰ meta_path ä½†æ²’æœ‰æä¾› metadataï¼Œç”¨é›¶å¡«å……
            batch_size = feat.shape[0]
            zero_meta = torch.zeros(batch_size, self.encoder.config.dim, device=feat.device)
            feat = torch.cat([feat, zero_meta], dim=-1)
            
        logits = self.classifier(self.dropout(feat))

        loss = None
        if labels is not None:
            loss = nn.CrossEntropyLoss()(logits, labels)

        return {"loss": loss, "logits": logits}
    
    def save_pretrained(self, save_directory):
        """ä¿å­˜æ¨¡å‹å’Œé…ç½®"""
        import os
        import json
        
        # ä¿å­˜config.json
        config_path = os.path.join(save_directory, "config.json")
        with open(config_path, 'w') as f:
            json.dump(self.config.to_dict(), f, indent=2)
        
        # ä¿å­˜æ¨¡å‹æ¬Šé‡
        model_path = os.path.join(save_directory, "pytorch_model.bin")
        torch.save(self.state_dict(), model_path)
        
        print(f"    ğŸ’¾ æ¨¡å‹å’Œé…ç½®å·²ä¿å­˜åˆ°: {save_directory}")
        
    @classmethod
    def from_pretrained(cls, model_path, **kwargs):
        """å¾ä¿å­˜çš„è·¯å¾‘è¼‰å…¥æ¨¡å‹"""
        import os
        import json
        
        # è¼‰å…¥config
        config_path = os.path.join(model_path, "config.json")
        if os.path.exists(config_path):
            with open(config_path, 'r') as f:
                config_dict = json.load(f)
            config = DualTowerConfig(**config_dict)
        else:
            # å¦‚æœæ²’æœ‰config.jsonï¼Œä½¿ç”¨é è¨­é…ç½®
            config = DualTowerConfig()
        
        # å‰µå»ºæ¨¡å‹
        model = cls(config=config)
        
        # è¼‰å…¥æ¬Šé‡
        model_path_file = os.path.join(model_path, "pytorch_model.bin")
        if os.path.exists(model_path_file):
            state_dict = torch.load(model_path_file, map_location='cpu')
            model.load_state_dict(state_dict)
        
        return model
